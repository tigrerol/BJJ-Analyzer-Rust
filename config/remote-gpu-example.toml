# BJJ Video Analyzer Configuration - Remote GPU Whisper Example
# This configuration demonstrates how to use a remote GPU server for transcription

[processing]
supported_extensions = ["mp4", "mkv", "avi", "mov", "webm", "m4v"]
max_file_size = 0  # No limit
skip_existing = true
validate_videos = true
enable_scene_detection = true

[audio]
target_sample_rate = 16000  # Optimal for Whisper
target_format = "wav"
enable_enhancement = true
enhancement_filters = "highpass=f=80,lowpass=f=8000,volume=1.2,dynaudnorm=g=3"
enable_chunking = false
chunk_duration = 300  # 5 minutes
cleanup_temp_files = true

[transcription]
# REMOTE GPU CONFIGURATION
provider = "Remote"  # Use remote GPU server
api_endpoint = "http://localhost:8080"  # Remote server URL
api_key = ""  # Not needed for local server

# Model and quality settings
model = "base"  # Model to use on remote server (tiny, base, small, medium, large, large-v3)
language = "en"  # Force English, or remove for auto-detection
auto_detect_language = false
temperature = 0.0  # Deterministic output
word_timestamps = true  # Include word-level timestamps

# Remote-specific settings
enable_fallback = true  # Fall back to local if remote fails
connection_timeout = 30  # Connection timeout in seconds
upload_chunk_size = 10485760  # 10MB upload chunks
max_retries = 3
timeout = 3600  # Overall timeout in seconds

# BJJ-specific optimization
use_bjj_prompts = true
bjj_terms_file = "config/bjj_terms.txt"
output_formats = ["SRT", "Text"]

# GPU settings (for local fallback)
use_gpu = false  # GPU not available locally
best_of = 3
beam_size = 5

[llm]
enable_correction = true
provider = "LMStudio"
endpoint = "http://localhost:1234/v1/chat/completions"
api_key = ""
model = "local-model"
max_tokens = 8192
temperature = 0.1
timeout_seconds = 120
prompt_file = "config/prompts/correction.txt"

[llm.prompts]
prompt_dir = "config/prompts"
correction_file = "correction.txt"
summary_high_level_file = "summary_high_level.txt"
summary_technical_file = "summary_technical.txt"
mermaid_flowchart_file = "mermaid_flowchart.txt"
whisper_transcription_file = "whisper_transcription.txt"

[chapters]
enable_detection = true
chapters_dir = "chapters"
request_timeout_seconds = 30
max_chapters = 100

[output]
base_dir = "./output"
dir_structure = "{date}/{video_name}"
enable_logging = true
log_level = "info"
save_metadata = true
export_formats = ["JSON"]

[performance]
max_workers = 4  # Parallel processing
memory_limit_mb = 1024
enable_monitoring = false
monitoring_port = 9090
enable_caching = true
cache_dir = "./cache"
cache_ttl = 3600